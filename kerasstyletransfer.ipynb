{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\n\nfrom keras.preprocessing.image import load_img, img_to_array\nfrom scipy.optimize import fmin_l_bfgs_b \nfrom keras.applications import vgg19\nfrom keras import backend as K\nfrom keras.preprocessing.image import save_img\n\nimport tensorflow as tf\n\ntf.compat.v1.disable_eager_execution() ","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:50:40.468041Z","iopub.execute_input":"2022-07-11T20:50:40.468459Z","iopub.status.idle":"2022-07-11T20:50:45.922251Z","shell.execute_reply.started":"2022-07-11T20:50:40.468369Z","shell.execute_reply":"2022-07-11T20:50:45.921256Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def preprocess_image(image_path, resized_width, resized_height):\n    img = load_img(image_path, target_size=(resized_width, resized_height))\n    img = img_to_array(img)\n    img = np.expand_dims(img, axis=0)\n    img = vgg19.preprocess_input(img)\n    return img\n\ndef deprocess_image(x, resized_width, resized_height):\n    x = x.reshape((resized_width, resized_height, 3))\n\n    # Remove zero-center by mean pixel. Necessary when working with VGG model\n    x[:, :, 0] += 103.939\n    x[:, :, 1] += 116.779\n    x[:, :, 2] += 123.68\n\n    # Format BGR->RGB\n    x = x[:, :, ::-1]\n    x = np.clip(x, 0, 255).astype('uint8')\n    return x\n\ndef save(filename, generated):\n    save_img(filename, Image.fromarray(generated))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:50:45.924004Z","iopub.execute_input":"2022-07-11T20:50:45.924612Z","iopub.status.idle":"2022-07-11T20:50:45.932685Z","shell.execute_reply.started":"2022-07-11T20:50:45.924575Z","shell.execute_reply":"2022-07-11T20:50:45.931812Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def gram_matrix(x):\n    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n    gram = K.dot(features, K.transpose(features))\n    return gram\n","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:50:45.934208Z","iopub.execute_input":"2022-07-11T20:50:45.934844Z","iopub.status.idle":"2022-07-11T20:50:45.944067Z","shell.execute_reply.started":"2022-07-11T20:50:45.934806Z","shell.execute_reply":"2022-07-11T20:50:45.942980Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def style_loss_per_layer(style, combination, resized_width, resized_height):\n    S = gram_matrix(style)\n    C = gram_matrix(combination)\n    channels = 3\n    size = resized_width * resized_height\n    return K.sum(K.square(S - C)) / (4. * (channels ** 2) * (size ** 2))\n\n\ndef total_style_loss(feature_layers, outputs_dict, resized_width, resized_height, style_weight):\n    loss = K.variable(0.)\n    for layer_name in feature_layers:\n        layer_features = outputs_dict[layer_name]\n        style_reference_features = layer_features[1, :, :, :]\n        combination_features = layer_features[2, :, :, :]\n        sl = style_loss_per_layer(style_reference_features, combination_features, resized_width, resized_height)\n        loss = loss + (style_weight / len(feature_layers)) * sl\n    return loss\n\n\ndef content_loss(layer_features):\n    base_image_features = layer_features[0, :, :, :]\n    combination_features = layer_features[2, :, :, :]\n    return K.sum(K.square(combination_features - base_image_features))\n\n\ndef total_variation_loss(x, resized_width, resized_height):\n    a = K.square(x[:, :resized_width - 1, :resized_height - 1, :] - x[:, 1:, :resized_height - 1, :])\n    b = K.square(x[:, :resized_width - 1, :resized_height - 1, :] - x[:, :resized_width - 1, 1:, :])\n    return K.sum(K.pow(a + b, 1.25))\n\n\ndef total_loss(outputs_dict, content_weight, resized_width, resized_height, style_weight, total_variation_weight, combination_image):\n    loss = K.variable(0.)\n\n    feature_layers_content = outputs_dict['block5_conv2']\n    loss = loss + content_weight * content_loss(feature_layers_content)\n\n    feature_layers_style = ['block1_conv1', 'block2_conv1',\n                            'block3_conv1', 'block4_conv1',\n                            'block5_conv1']\n    loss = loss + total_style_loss(feature_layers_style, outputs_dict, resized_width, resized_height, style_weight) * style_weight\n\n    loss = loss + total_variation_weight * total_variation_loss(combination_image, resized_width, resized_height)\n    \n    return loss","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-11T20:50:46.778278Z","iopub.execute_input":"2022-07-11T20:50:46.778618Z","iopub.status.idle":"2022-07-11T20:50:46.792427Z","shell.execute_reply.started":"2022-07-11T20:50:46.778589Z","shell.execute_reply":"2022-07-11T20:50:46.791273Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def eval_loss_and_grads(x, resized_width, resized_height, f_outputs):\n    x = x.reshape((1, resized_width, resized_height, 3))\n    outs = f_outputs([x])\n    loss_value = outs[0]\n    if len(outs[1:]) == 1:\n        grad_values = outs[1].flatten().astype('float64')\n    else:\n        grad_values = np.array(outs[1:]).flatten().astype('float64')\n    return loss_value, grad_values\n\nclass Evaluator(object):\n    def __init__(self, resized_width, resized_height, f_outputs):\n        self.loss_value = None\n        self.grads_values = None\n        self.resized_width = resized_width\n        self.resized_height = resized_height\n        self.f_outputs = f_outputs\n        \n    def loss(self, x):\n        assert self.loss_value is None\n        loss_value, grad_values = eval_loss_and_grads(x, self.resized_width, self.resized_height, self.f_outputs)\n        self.loss_value = loss_value\n        self.grad_values = grad_values\n        return self.loss_value\n\n    def grads(self, x):\n        assert self.loss_value is not None\n        grad_values = np.copy(self.grad_values)\n        self.loss_value = None\n        self.grad_values = None\n        return grad_values\n","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:50:48.355661Z","iopub.execute_input":"2022-07-11T20:50:48.356349Z","iopub.status.idle":"2022-07-11T20:50:48.367867Z","shell.execute_reply.started":"2022-07-11T20:50:48.356310Z","shell.execute_reply":"2022-07-11T20:50:48.365001Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def run(content_path, style_path, itr, filename):\n    # Variables declaration\n    base_image_path = content_path\n    style_reference_image_path = style_path\n    iterations = itr\n    \n    # Weights to compute the final loss\n    total_variation_weight = 0\n    style_weight = 2\n    content_weight = 5\n    \n    # Dimensions of the generated picture.\n    width, height = load_img(base_image_path).size\n    resized_width = 512\n    resized_height = int(width * resized_width / height)\n    \n    # Get tensor representations of our images\n    base_image = K.variable(preprocess_image(base_image_path, resized_width, resized_height))\n    style_reference_image = K.variable(preprocess_image(style_reference_image_path, resized_width, resized_height))\n    \n    # Placeholder for generated image\n    combination_image = K.placeholder((1, resized_width, resized_height, 3))\n    \n    # Combine the 3 images into a single Keras tensor\n    input_tensor = K.concatenate([base_image,\n                                  style_reference_image,\n                                  combination_image], axis=0)\n    \n    # Build the VGG19 network with our 3 images as input\n    # the model is loaded with pre-trained ImageNet weights\n    model = vgg19.VGG19(input_tensor=input_tensor,weights='imagenet', include_top=False)\n    \n    # Get the outputs of each key layer, through unique names.\n    outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n    loss = total_loss(outputs_dict, content_weight, resized_width, resized_height, style_weight, total_variation_weight, combination_image)\n    \n    # Get the gradients of the generated image\n    grads = K.gradients(loss, combination_image)\n    outputs = [loss]\n    outputs += grads\n    \n    f_outputs = K.function([combination_image], outputs)\n    \n    evaluator = Evaluator(resized_width, resized_height, f_outputs)\n\n    x = preprocess_image(base_image_path, resized_width, resized_height)\n    \n    # The oprimizer is fmin_l_bfgs\n    for i in range(iterations):\n        print('Iteration: ', i)\n        x, min_val, info = fmin_l_bfgs_b(evaluator.loss,\n                                         x.flatten(),\n                                         fprime=evaluator.grads,\n                                         maxfun=25)\n    \n        print('Current loss value:', min_val)\n    \n        # Save current generated image\n        img = deprocess_image(x.copy(), resized_width, resized_height)\n        fname = str(i) + '.png'\n    plt.figure()\n    plt.title(\"Generated Image\")\n    plt.imshow(img)\n    save(filename, img)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:55:03.943334Z","iopub.execute_input":"2022-07-11T20:55:03.943790Z","iopub.status.idle":"2022-07-11T20:55:03.965378Z","shell.execute_reply.started":"2022-07-11T20:55:03.943738Z","shell.execute_reply":"2022-07-11T20:55:03.964270Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    \n    # Change the file path and the iteration value as desired\n    filename = \"people2.jpg\"\n    content_path = \"../input/style-transfer-files/Content/people2.jpg\"\n    style_path = \"../input/style-transfer-files/Style/1.jpg\"\n    itr = 5\n    \n    run( content_path, style_path, itr, filename)\n    \n    filename = \"city0.jpg\"\n    content_path = \"../input/style-transfer-files/Content/city0.jpg\"\n    style_path = \"../input/style-transfer-files/Style/0.jpg\"\n    itr = 5\n    \n    run( content_path, style_path, itr, filename)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T20:55:05.493402Z","iopub.execute_input":"2022-07-11T20:55:05.493812Z","iopub.status.idle":"2022-07-11T20:56:43.391454Z","shell.execute_reply.started":"2022-07-11T20:55:05.493777Z","shell.execute_reply":"2022-07-11T20:56:43.390394Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}